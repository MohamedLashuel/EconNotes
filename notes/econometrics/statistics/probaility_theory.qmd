---
title: "Random Variables"
---

**Probability Mass Function** $p_X(x)$ for a discrete variable $X$ is defined as $P(X = x)$

**Probability Density Function** $f_X(x)$ for a continuous variable $X$ is defined such that $\int_a^b f_X(x)dx = P(a \le X \le b)$

**Cumulative Density Function** $F_X(x)$ for a continuous variable $X$ is defined such that $F(a) = P(X \le a)$

## Properties of Probability

- $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
  - $P(A \cap B) = P(A) + P(B) - P(A \cup B)$
- If $A$ and $B$ are independent, $P(A \cap B) = P(A)P(B)$
- $P(A | B) = \frac{P(A \cap B)}{P(B)}$
  - If $A$ and $B$ are independent, $P(A | B) = P(A)$
- $P(A \cap B^c) = P(A) - P(A \cap B)$
- **Bayes Theorem**: $P(A|B) = \frac{P(B|A)P(A)}{P(B)}$

## Expected Value

**Expected value** of a random variable $X$ denoted $E(X)$ or $\mu_X$ is the average value X is expected to be.

- $E(X)$ for a discrete random variable $X$ is $\sum_{x \in X} P(X = x)x$
- $E(X)$ for a continuous random variable $X$ is $\int_Xf(x)x$

Properties of expected value:

- $E(X + Y) = E(X) + E(Y)$
- $E(aX + b) = aE(X) + b$ (linearity of expectation)
- $E(a) = a$
- If $X$ and $Y$ are independent, $E(XY) = E(X)E(Y)$
- $E(g(X)) = \sum_{x \in X} P(X = x)g(x)$ or $\int_{X} f_X(x)g(x)dx$

**Conditional Expected Value** $E(X | Y = y)$ is a function of $y$ which gives the expected value of $X$ conditional to $Y = y$. It is calculated as $\sum_{x \in X}xP(X = x | Y = y)$ or $\int_X xf_X(x | Y = y) dx$

- If $X$ and $Y$ are independent, $E(X | Y) = E(X)$

**Law of Iterated Expectations**: $E(X) = E(E(X | Y))$

### Other moments of X

**Variance** $\sigma^2_X$ or $Var(X)$, the second central moment of $X$, is a measure of spread of a random variable and is calculated as $E((X - E(X))^2)$

- Also equals $E(X^2) - \mu_X^2$
- $Var(aX + b) = a^2Var(X)$
- $Var(X + Y) = Var(X) + Var(Y) + 2Cov(X, Y)$

**Skewness** $SK$, the standardized third central moment of $X$, is a measure of if $X$ is symmetric or skewed and is calculated as $\frac{E(X - E(X))^3}{\sigma_X^3}$

- X is symmetric if $SK = 0$, skewed right if $SK > 0$, and skewed left if $SK < 0$

**Kurtosis** $K$, the standardized fourth central moment of $X$, is a measure of the weight of $X$'s tails and is calculated as $\frac{E(X - E(X))^4}{\sigma_X^4}$

- Tails are considered heavy if $K > 3$ (leptokurtism) as opposed to $K = 3$ (mesokurtic) or $K < 3$ (platykurtic)

### Covariance

**Covariance** of random variables $X$ and $Y$ denoted $\sigma_{X, Y}$ measures how well $X$ and $Y$ vary together and is calculated as $E((X - \mu_X)(Y - \mu_Y))$ or $E(XY) - \mu_X\mu_Y$

**Correlation** $\rho_{X, Y}$ is standardized covariance $\frac{\sigma_{X, Y}}{\sigma_X\sigma_Y}$ and measures how related $X$ and $Y$ are
